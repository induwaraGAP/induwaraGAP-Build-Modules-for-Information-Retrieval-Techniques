{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "########=======   Q1) ================================= \n",
    "import os\n",
    "\n",
    "#IT NO : IT18140712\n",
    "#NAME : INDUWARA GAP\n",
    "#BATCH : DS BATCH 3rd Year 2nd semester Weekend\n",
    "\n",
    "#a). Write a program to identify the terms in the document.\t\n",
    "#execute the following \n",
    "#all the test cases have done\n",
    "#use the  docs 1.txt  5.txt  6.txt 9.txt \n",
    "def getTerm():\n",
    "    \n",
    "    #to store the term and the docs\n",
    "    term_doc_dict ={}\n",
    "   \n",
    "    #get current working directory\n",
    "    cd =  os.getcwd()   \n",
    "    \n",
    "    #path to the machine folder  \n",
    "    path =  'D:\\\\Sllit assignements\\\\3RD 2ND\\\\IRWA\\\\Assignement 1'\n",
    "    filelist = os.listdir(path)   \n",
    "    \n",
    "    #read the file through for loop\n",
    "    for file   in filelist:\n",
    "        \n",
    "        #open files as read mode\n",
    "        with open(file,'r') as f:\n",
    "            \n",
    "            #read the sentence and split by space\n",
    "            words = f.read().lower().split()           \n",
    "            \n",
    "            for word in words:\n",
    "                \n",
    "                #remove special characters\n",
    "                if word[-1] in [',','!','?','.']:\n",
    "                    word =  word[:-1]\n",
    "                \n",
    "                #if word not in the term_doc_dict add the word else update teh existing entry in the else section\n",
    "                if word not in term_doc_dict.keys():\n",
    "                    \n",
    "                    #remove the txt part of the file and just save the filename and the term in the dictionary\n",
    "                    term_doc_dict[word] = [f.name[:file.find(\".txt\")]]\n",
    "                else:\n",
    "                    \n",
    "                    if file[:file.find(\".txt\")] not in term_doc_dict[word]:\n",
    "                        term_doc_dict[word] += [f.name[:file.find(\".txt\")]]\n",
    "        \n",
    "    return term_doc_dict,filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the function getTerm()\n",
    "store_out_put = getTerm()\n",
    "\n",
    "#copy the terms to a seperate list \n",
    "term_list = list(store_out_put[0].keys())\n",
    "\n",
    "#copy the filenames to a seperate list by removing 'txt' at the end\n",
    "file_list =[filename[:filename.find(\".txt\")] for filename in store_out_put[1]]\n",
    "\n",
    "#get all terms and doc ids\n",
    "term_doc_dict =store_out_put[0] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D1': [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'D2': [1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0], 'D3': [0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1], 'Terms': ['frodo', 'stabbed', 'the', 'orc', 'with', 'red', 'sword', 'and', 'sam', 'used', 'blue', 'lamp', 'to', 'locate', 'orcs', 'killed', 'many', 'in', 'mordor']}\n"
     ]
    }
   ],
   "source": [
    "#get all the terms,D1,D2,D3 and related terms  to a dictionary to show the term document incience matric more efficiently\n",
    "# 1 if the term exist in the doc else 0\n",
    "TDIM = {} #Term Document Incidence Matrix\n",
    "for doc in file_list:\n",
    "    TDIM[doc] = []\n",
    "    for term in term_list:\n",
    "        \n",
    "        if doc in term_doc_dict[term]:\n",
    "            TDIM[doc] +=[1]\n",
    "        else :\n",
    "            TDIM[doc] += [0]\n",
    "        \n",
    "#add the terms also to the TDIM\n",
    "TDIM[\"Terms\"] = term_list;    \n",
    "\n",
    "print(TDIM)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Terms  D1  D2  D3\n",
      "0     frodo   1   1   0\n",
      "1   stabbed   1   0   0\n",
      "2       the   1   1   1\n",
      "3       orc   1   0   0\n",
      "4      with   1   0   1\n",
      "5       red   1   0   0\n",
      "6     sword   1   0   1\n",
      "7       and   0   1   0\n",
      "8       sam   0   1   1\n",
      "9      used   0   1   0\n",
      "10     blue   0   1   1\n",
      "11     lamp   0   1   0\n",
      "12       to   0   1   0\n",
      "13   locate   0   1   0\n",
      "14     orcs   0   1   1\n",
      "15   killed   0   0   1\n",
      "16     many   0   0   1\n",
      "17       in   0   0   1\n",
      "18   mordor   0   0   1\n"
     ]
    }
   ],
   "source": [
    "#now we have the docs and their respective related terms  \n",
    "#copy them 'term_doc_inc_matrix' dataframe\n",
    "\n",
    "#===============     b). Build a term document incidence matrix\t =====================\n",
    "import pandas as pd\n",
    "term_doc_inc_matrix= pd.DataFrame(TDIM, columns=['Terms', 'D1','D2','D3'])\n",
    "\n",
    "#Term Document Incidence Matrix\n",
    "print(term_doc_inc_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    c). Using the above matrix identify the documents that are relevant for the following queries? \n",
    "#      q1: (Frodo AND orc AND sword)\t\t\t\t\t(5 Marks)\n",
    "#    q2: (Sam AND blue AND NOT Frodo)\t\n",
    "\n",
    "\n",
    "\n",
    "#logical operators\n",
    "# AND operation function, use INTERSECTION\n",
    "\n",
    "def AND_operation(l1,l2):\n",
    "    if((l1) and (l2)):\n",
    "        return set(l1).intersection(l2)\n",
    "    else:\n",
    "        return set()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR operation function,  use UNION\n",
    "\n",
    "def OR_operation(l1,l2):\n",
    "    return set(l1).union(l2)\n",
    "\n",
    "# NOT operation function,  use SYMMETRIC_DIFFERENCE\n",
    "\n",
    "def NOT_operation(l1):\n",
    "    return set(file_list).symmetric_difference(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer for  : Frodo AND orc AND sword\n",
      "{'D1'}\n"
     ]
    }
   ],
   "source": [
    "# q1: (Frodo AND orc AND sword)\n",
    "print(\"Answer for  : Frodo AND orc AND sword\")\n",
    "list1 = term_doc_dict['frodo']\n",
    "list2 = term_doc_dict['orc']\n",
    "list3 = term_doc_dict['sword']\n",
    "\n",
    "result = AND_operation( AND_operation(list1,list2),list3)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer for  : Sam AND blue AND NOT Frodo\n",
      "{'D2'}\n"
     ]
    }
   ],
   "source": [
    "#q2: (Sam AND blue AND NOT Frodo)\n",
    "print(\"Answer for  : Sam AND blue AND NOT Frodo\")\n",
    "list1 = term_doc_dict['sam']\n",
    "list2 = term_doc_dict['blue']\n",
    "list3 = term_doc_dict['sword']\n",
    "\n",
    "#get not FRODO first\n",
    "not_result = NOT_operation(list3)\n",
    "\n",
    "#then AND it with Sam AND blue\n",
    "result = AND_operation( AND_operation(list1,list2),not_result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========       Q2). \n",
    "\n",
    "###         1.\tBuild modules to tokenize words and sentences.\t\n",
    "\n",
    "##function to remove special characters\n",
    "def special_character_remove(word):\n",
    "    \n",
    "    checkword =list(word) #make list with inserted word\n",
    "    \n",
    "    correct = []         #to collect the correct words without special characters\n",
    "    \n",
    "    for i in range(len(checkword)):\n",
    "        \n",
    "        if checkword[i] not in [\"!\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\"(\",\")\",\"~\",\"`\",\"-\",\"_\",\"=\",\"+\",\"[\",\"]\",\"{\",\"}\",\";\",\":\",\"'\",'\"\"',\"?\",\"/\",\">\",\"<\",\".\",\",\"]:\n",
    "            correct.append(checkword[i])      \n",
    "    \n",
    "    ##then join the correct letters using join operator to return as string\n",
    "    \n",
    "    return \"\".join(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test special_character_remove :>> \n",
      "\n",
      "abc$%@ghf&$  --> abcghf\n",
      "#$he*ll@#$o  --> hello\n",
      "w$%#o%^rl@#&:d  --> world\n"
     ]
    }
   ],
   "source": [
    "#Test the special character remover function\n",
    "print(\"Test special_character_remove :>> \\n\")\n",
    "print( \"abc$%@ghf&$  --> \"  + special_character_remove(\"abc$%@ghf&$\"))\n",
    "print( \"#$he*ll@#$o  --> \"  + special_character_remove(\"#$he*ll@#$o\"))\n",
    "print( \"w$%#o%^rl@#&:d  --> \"  + special_character_remove(\"w$%#o%^rl@#&:d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#impprt nltk \n",
    "\n",
    "import nltk\n",
    "nltk.download()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###1.\tBuild modules to tokenize words and sentences.\t\n",
    "\n",
    "import os\n",
    "\n",
    "#use special_character_remove to remove the special character of each read word \n",
    "def getTermSent():\n",
    "    \n",
    "    term_doc_dict ={}\n",
    "    sent_doc_dict ={}\n",
    "    \n",
    "    #get current working directory\n",
    "    cd =  os.getcwd()\n",
    "    \n",
    "     #path to the machine folder   \n",
    "   \n",
    "    path =  'D:\\\\Sllit assignements\\\\3RD 2ND\\\\IRWA\\\\Assignmenr 1 q2\\\\tr'\n",
    "    filelist = os.listdir(path)  \n",
    "    \n",
    "    \n",
    "    #read the file through for loop\n",
    "    for file   in filelist:       \n",
    "       \n",
    "        \n",
    "        #open file fo\n",
    "        with open(file,'r') as f:\n",
    "            r = f.read()\n",
    "            \n",
    "             #read the sentence and split by space\n",
    "            words = r.upper().split()             \n",
    "           \n",
    "            #spilt the sentences and add them to a seperate dictionary 'sent_doc_dict'\n",
    "            text = r.lower().split(\".\")             \n",
    "            docname = f.name[:file.find(\".txt\")]                             \n",
    "            if docname not in sent_doc_dict.keys():\n",
    "                sent_doc_dict[docname] = [text]\n",
    "            else:\n",
    "                sent_doc_dict[docname] += [text]\n",
    "            \n",
    "             #read the words tokenized through for loop\n",
    "            for word in words:\n",
    "                \n",
    "                #remove special characters using function\n",
    "                word =  special_character_remove(word).strip()\n",
    "                \n",
    "                 #remove the txt part of the file and just save the filename and the term in the dictionary                    \n",
    "                if word not in term_doc_dict.keys():\n",
    "                    term_doc_dict[word] = [f.name[:file.find(\".txt\")]]\n",
    "                else:\n",
    "                    if file[:file.find(\".txt\")] not in term_doc_dict[word]:\n",
    "                        term_doc_dict[word] += [f.name[:file.find(\".txt\")]]\n",
    "        \n",
    "    return term_doc_dict,filelist,sent_doc_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['BAHIA', 'COCOA', 'REVIEW', 'SHOWERS', 'CONTINUED', 'THROUGHOUT', 'THE', 'WEEK', 'IN', 'ZONE', 'ALLEVIATING', 'DROUGHT', 'SINCE', 'EARLY', 'JANUARY', 'AND', 'IMPROVING', 'PROSPECTS', 'FOR', 'COMING', 'TEMPORAO', 'ALTHOUGH', 'NORMAL', 'HUMIDITY', 'LEVELS', 'HAVE', 'NOT', 'BEEN', 'RESTORED', 'COMISSARIA', 'SMITH', 'SAID', 'ITS', 'WEEKLY', 'DRY', 'PERIOD', 'MEANS', 'WILL', 'BE', 'LATE', 'THIS', 'YEAR', 'ARRIVALS', 'ENDED', 'FEBRUARY', '22', 'WERE', '155221', 'BAGS', 'OF', '60', 'KILOS', 'MAKING', 'A', 'CUMULATIVE', 'TOTAL', 'SEASON', '593', 'MLN', 'AGAINST', '581', 'AT', 'SAME', 'STAGE', 'LAST', 'AGAIN', 'IT', 'SEEMS', 'THAT', 'DELIVERED', 'EARLIER', 'ON', 'CONSIGNMENT', 'WAS', 'INCLUDED', 'FIGURES', 'THERE', 'IS', 'STILL', 'SOME', 'DOUBT', 'AS', 'TO', 'HOW', 'MUCH', 'OLD', 'CROP', 'AVAILABLE', 'HARVESTING', 'HAS', 'PRACTICALLY', 'COME', 'AN', 'END', 'WITH', 'ESTIMATES', 'AROUND', '64', 'SALES', 'STANDING', 'ALMOST', '62', 'ARE', 'FEW', 'HUNDRED', 'THOUSAND', 'HANDS', 'FARMERS', 'MIDDLEMEN', 'EXPORTERS', 'PROCESSORS', 'DOUBTS', 'WOULD', 'FIT', 'EXPORT', 'SHIPPERS', 'NOW', 'EXPERIENCING', 'DIFICULTIES', 'OBTAINING', 'SUPERIOR', 'CERTIFICATES', 'VIEW', 'LOWER', 'QUALITY', 'OVER', 'RECENT', 'WEEKS', 'SOLD', 'GOOD', 'PART', 'THEIR', 'HELD', 'SPOT', 'BEAN', 'PRICES', 'ROSE', '340', '350', 'CRUZADOS', 'PER', 'ARROBA', '15', 'RELUCTANT', 'OFFER', 'NEARBY', 'SHIPMENT', 'ONLY', 'LIMITED', 'BOOKED', 'MARCH', '1750', '1780', 'DLRS', 'TONNE', 'PORTS', 'NAMED', 'NEW', 'ALSO', 'LIGHT', 'ALL', 'OPEN', 'JUNEJULY', 'GOING', '1850', '1880', '35', '45', 'UNDER', 'YORK', 'JULY', 'AUGSEPT', '1870', '1875', 'FOB', 'ROUTINE', 'BUTTER', 'MADE', 'MARCHAPRIL', '4340', '4345', '4350', 'APRILMAY', 'WENT', '227', 'TIMES', 'MAY', '4400', '4415', '4351', '4450', '228', 'SEPT', 'OCTDEC', '4480', 'DEC', 'DESTINATIONS', 'US', 'COVERTIBLE', 'CURRENCY', 'AREAS', 'URUGUAY', 'CAKE', 'REGISTERED', '785', '995', '753', 'AUG', '039', 'BUYERS', 'ARGENTINA', 'CONVERTIBLE', 'LIQUOR', 'SELLING', '2325', '2380', '2375', '125', '2400', 'CURRENTLY', 'ESTIMATED', '613', '198687', '106', '198788', 'FINAL', '28', 'EXPECTED', 'PUBLISHED', 'BY', 'BRAZILIAN', 'TRADE', 'COMMISSION', 'AFTER', 'CARNIVAL', 'WHICH', 'ENDS', 'MIDDAY', '27', 'NATIONAL', 'AVERAGE', 'FARMEROWNED', 'RESERVE', 'AGRICULTURE', 'DEPARTMENT', 'REPORTED', 'FIVEDAY', 'PRICE', 'THROUGH', '25', 'FOLLOWS', 'DLRSBUSORGHUM', 'CWT', '', 'NATL', 'LOAN', 'RELEASE', 'CALL', 'AVGE', 'RATEX', 'LEVEL', 'WHEAT', '255', '240', 'IV', '465', 'V', 'VI', '445', 'CORN', '135', '192', '315', '325', 'X', '1986', 'RATES', 'OATS', '124', '099', '165', 'BARLEY', 'NA', '156', '265', 'SORGHUM', '234', '325Y', '536', '554', 'RESERVES', 'I', 'II', 'III', 'MATURED', 'REFLECTS', 'GRAIN', 'ENTERED', 'OCT', '6', '1981', 'FEEDGRAIN', '23', 'WHEATBARLEY', '51482', 'CORNSORGHUM', '7182', 'COVERS', '19', '1984', 'X1986', 'YDLRS', '100', 'LBS', 'NANOT', 'ARGENTINE', 'GRAINOILSEED', 'REGISTRATIONS', 'BOARD', 'SHOW', 'GRAINS', 'OILSEEDS', 'PRODUCTS', '11', 'THOUSANDS', 'TONNES', 'SHOWING', 'THOSE', 'FUTURE', 'SHIPMENTS', 'MONTH', '198586', '12', 'BRACKETS', 'BREAD', 'PREV', '16558', 'FEB', '8720', '1646', '26924', '41610', 'MAIZE', 'MAR', '480', 'NIL', 'OILSEED', 'SUNFLOWERSEED', '150', '79', 'SOYBEAN', '200', 'DETAILED', 'SUBPRODUCTS', '399', '487', '132', 'APR', '1118', '827', 'LINSEED', '348', '329', '68', '63', '808', '874', '1009', '451', '1661', '2185', '486', '615', '251', '145', '1498', '1453', 'VEGETABLE', 'OIL', 'SUNOIL', '374', '1073', '245', '32', 'JUN', '1824', '1176', 'LINOIL', '159', '236', '204', '20', '618', '761', '37', '211', '90', '130', 'JUL', '70', '558', '337', 'REUTER', 'CHAMPION', 'LTCH', 'APPROVES', 'STOCK', 'SPLIT', 'INC', 'DIRECTORS', 'APPROVED', 'TWOFORONE', 'COMMON', 'SHARES', 'SHAREHOLDERS', 'RECORD', 'APRIL', '1', '1987', 'COMPANY', 'VOTED', 'RECOMMEND', 'ANNUAL', 'MEETING', 'INCREASE', 'AUTHORIZED', 'CAPITAL', 'FROM', 'FIVE'])\n"
     ]
    }
   ],
   "source": [
    "# run the function \n",
    "output = getTermSent()\n",
    "\n",
    "###     tokenize words \n",
    "print(output[0].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###       2.\tBuild module for Porter Stemmer to do stemming.\t\n",
    "\n",
    "#initialize the dictionaries for each step of porters algorithm\n",
    "stepOnedict = {\"SSES\":\"SS\", \"IES\":\"I\",\"SS\":\"SS\",\"S\":\"\" }\n",
    "\n",
    "#     step 1 of porters algorithm\n",
    "#word that need to be put in step 1\n",
    "\n",
    "def stepOneA(word):\n",
    "    #get the suffix of last3 words\n",
    "    word = word.upper().strip()\n",
    "    \n",
    "    if(len(word)>= 4):\n",
    "        \n",
    "        for upto in range(4,0,-1):\n",
    "            \n",
    "            #seperate the suffix from term\n",
    "            last = word[len(word)-upto:]\n",
    "            stem = word[ :len(word)-upto]\n",
    "            \n",
    "            ## replace with term in the stepOnedict dictionary\n",
    "            if last in stepOnedict.keys() :\n",
    "                word =  stem + stepOnedict[last]\n",
    "                return word      \n",
    "    \n",
    "    return word\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test step 1  :>>\n",
      "caresses -> caress\n",
      "cats -> cat\n"
     ]
    }
   ],
   "source": [
    "##test step 1\n",
    "print(\"Test step 1  :>>\")\n",
    "print(\"caresses -> \"+stepOneA(\"caresses\").lower())\n",
    "print(\"cats -> \"+stepOneA(\"cats \").lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vowel = [\"A\",\"E\",\"I\",\"O\",\"U\"]\n",
    "\n",
    "##     cal of M\n",
    "\n",
    "#word : word that needed to be stem\n",
    "\n",
    "def CalMeasure(word):\n",
    "    measure = 0;\n",
    "    \n",
    "    word = word.upper().strip()\n",
    "    \n",
    "    ## using for loop check the occurence of CV using vowel list\n",
    "    previous =  word[0]    \n",
    "    for letter in word:\n",
    "        current =  letter        \n",
    "        if( (current not in vowel) and (previous  in vowel) ):\n",
    "            measure = measure + 1\n",
    "        previous =  current\n",
    "    return measure\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test CalMeasure :>> \n",
      "troubles  -> m =  2\n"
     ]
    }
   ],
   "source": [
    "#test Measure\n",
    "print(\"test CalMeasure :>> \")\n",
    "print(\"troubles  -> m =  \"+ str(CalMeasure(\"TROUBLES\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##need to check whether there is vowel in the stem using vowel list\n",
    "# return if vowel exits or not(True or False)\n",
    "def CheckVowel(word,upto):\n",
    "    \n",
    "    word = word.upper().strip()\n",
    "    \n",
    "    vowelstatus = False;\n",
    "    \n",
    "    #check for the validity of the word\n",
    "    if(len(word)- upto >= 0):\n",
    "        for letter in word[: len(word)-upto]:\n",
    "            if letter in vowel:\n",
    "                vowelstatus =  True\n",
    "                break\n",
    "                \n",
    "    return vowelstatus\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for the CheckVowel :> \n",
      "plastered  ->  True\n",
      "gfv  ->  False\n"
     ]
    }
   ],
   "source": [
    "#Test Vowel\n",
    "\n",
    "print(\"Test for the CheckVowel :> \")\n",
    "print(\"plastered  ->  \" + str(CheckVowel(\"plastered\",2) ) )\n",
    "print(\"gfv  ->  \" + str(CheckVowel(\"gfv\",2) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check  *d - the stem ends with a double consonant (e.g. -TT, -SS).\n",
    "## return exist or not (True or False)\n",
    "\n",
    "def CheckD(word):\n",
    "    \n",
    "    word = word.upper().strip()\n",
    "    \n",
    "    if(len(word) >= 2):\n",
    "        \n",
    "        #seperate the suffix from term\n",
    "        last1 = word[len(word)-1]\n",
    "        last2 = word[len(word)-2]    \n",
    "        \n",
    "        #check for last letters are same and whether both are consonant\n",
    "        if ((last1 == last2) and (last1 not in vowel) and (last2 not in vowel) ):\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for the stem ends with a double consonant (e.g. -TT, -SS). \n",
      "hopp -> True\n",
      "cat -> False\n"
     ]
    }
   ],
   "source": [
    "#test for D\n",
    "\n",
    "print(\"Test for the stem ends with a double consonant (e.g. -TT, -SS). \")\n",
    "print(\"hopp -> \" +str(CheckD(\"hopp\")) )\n",
    "print(\"cat -> \" +str(CheckD(\"cat\")) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method to check whether given last word exist\n",
    "#return exist or not (True or False)\n",
    "\n",
    "def CheckLastWord(word,givenlast):\n",
    "    word = word.upper().strip()\n",
    "    last = word[len(word)-1]\n",
    "    givenlast = givenlast.upper().strip()\n",
    "    if(last == givenlast ):\n",
    "        return True\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ends in 'd'\n",
      "word -> True\n",
      "Test ends in 's'\n",
      "bass -> True\n"
     ]
    }
   ],
   "source": [
    "#test CheckLastWord\n",
    "\n",
    "print(\"Test ends in 'd'\")\n",
    "print(\"word -> \"+  str (CheckLastWord(\"word\",\"d\")) )\n",
    "print(\"Test ends in 's'\")\n",
    "print(\"bass -> \"+  str (CheckLastWord(\"bass\",\"s\")) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  *O - the stem ends cvc, where the second c is not W, X or Y (e.g. -WIL, -HOP).\n",
    "#return trie or false\n",
    "\n",
    "def CheckCVC(word):    \n",
    "    word = word.upper().strip()\n",
    "    \n",
    "    if(len(word) >= 3):\n",
    "        \n",
    "        #spilt last three letter from given word\n",
    "        last1 = word[len(word)-3]\n",
    "        last2 = word[len(word)-2]\n",
    "        last3 = word[len(word)-1]\n",
    "        \n",
    "        #check for the CVC condition and second C letter not in [\"W\",\"X\",\"Y\"]\n",
    "        if ((last1 not in vowel) and (last2 in vowel) and (last3 not in vowel)):\n",
    "\n",
    "            if(last3 not in [\"W\",\"X\",\"Y\"]):\n",
    "\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test check *o - the stem ends cvc where the second c is not W, X or Y :>\n",
      "WIL --> True\n",
      "SIX (X  in the end) --> False\n"
     ]
    }
   ],
   "source": [
    "#check *o - the stem ends cvc where the second c is not W, X or Y (e.g. -WIL, -HOP).\n",
    "print(\"test check *o - the stem ends cvc where the second c is not W, X or Y :>\") \n",
    "print(\"WIL --> \" +    str(CheckCVC(\"WIL\") ) )\n",
    "print(\"SIX (X  in the end) --> \" +   str(  CheckCVC(\"SIX\") ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the dictionaries for each step of porters algorithm\n",
    "stepOneBdict = {\"EED\":\"EE\", \"ED\":\"\",\"ING\":\"\",\"S\":\"\",\"AT\":\"ATE\",\"BL\":\"BLE\",\"IZ\":\"IZE\"}\n",
    "\n",
    "######    step 1 .B of Porter Stemmer algorithm\n",
    "\n",
    "#use CalMeasure() to get the measure\n",
    "#use CheckLastWord() to check whether the given word end in the given letter\n",
    "#use CheckD() to check whether  stem ends with a double consonant \n",
    "#use CheckCVC() to check  the stem ends cvc, where the second c is not W, X or Y\n",
    "#use CheckVowel() to check whether the given word include any vowel \n",
    "def stepOneB(word):\n",
    "    word = word.upper().strip()\n",
    "    \n",
    "    #first resolve issues with 3 word suffix\n",
    "    last3 = word[len(word)-3:] \n",
    "    last2 = word[len(word)-2:] \n",
    "    last1 = word[len(word)-1:]\n",
    "    stem3 = word[:len(word)-3]\n",
    "    stem2 = word[:len(word)-2]\n",
    "    stem1 = word[:len(word)-1]\n",
    "    \n",
    "    #CHECK THE CONDITION IN THE STEP 1.B\n",
    "    if( (last3 == \"EED\") and (CalMeasure(word)>0) ):\n",
    "        \n",
    "        word =  stem3 + stepOneBdict[last3]    \n",
    "        \n",
    "    if( (last3 == \"ING\") and (CheckVowel(word,3)==True) ):     \n",
    "        \n",
    "        #get last two words from stem3\n",
    "        stemlast2 = stem3[len(stem3)-2:]\n",
    "        \n",
    "        if( ( CheckLastWord(stem3,\"L\") == False) and \n",
    "           ( CheckLastWord(stem3,\"S\") == False) and\n",
    "            ( CheckLastWord(stem3,\"Z\") == False) and (CheckD(stem3)==True) ):\n",
    "            \n",
    "            word =  stem3[:len(stem3)-1] + stepOneBdict[last3]\n",
    "            \n",
    "        elif ( (CalMeasure(word) == 1) and (CheckCVC(stem3) == True) ):\n",
    "            \n",
    "            word = stem3 + \"E\"\n",
    "        else:\n",
    "            word =  stem3 + stepOneBdict[last3]\n",
    "            \n",
    "    elif( (last2 ==\"ED\") and (CheckVowel(word,2)==True) )  :\n",
    "        \n",
    "        #get the last two words from stem2\n",
    "        stemlast2 = stem2[len(stem2)-2:]\n",
    "        \n",
    "        if( ( CheckLastWord(stem2,\"L\") == False) and \n",
    "           ( CheckLastWord(stem2,\"S\") == False) and\n",
    "            ( CheckLastWord(stem2,\"Z\") == False) and (CheckD(stem2)==True) ):\n",
    "            \n",
    "            word =  stem2[:len(stem2)-1] + stepOneBdict[last2]\n",
    "        \n",
    "        elif (stemlast2 ==\"AT\"):\n",
    "           \n",
    "            word =  stem2[:len(stem2)-2] + stepOneBdict[stemlast2]\n",
    "        \n",
    "        elif (stemlast2 ==\"BL\"):\n",
    "           \n",
    "            word =  stem2[:len(stem2)-2] + stepOneBdict[stemlast2]    \n",
    "            \n",
    "        elif (stemlast2 ==\"IZ\"):\n",
    "            \n",
    "            word =  stem2[:len(stem2)-2] + stepOneBdict[stemlast2]\n",
    "        else:\n",
    "            \n",
    "            word =  stem2 + stepOneBdict[last2]\n",
    "            \n",
    "    elif( last1 == \"S\" ):\n",
    "        \n",
    "        word =  stem1 + stepOneBdict[last1]\n",
    "        \n",
    "    return word;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test step 1.B  :> \n",
      "motoring -> motor\n",
      "plastered  -> plaster\n",
      "agreed  -> agre\n"
     ]
    }
   ],
   "source": [
    "#check step 1.b\n",
    "\n",
    "######    step 1 .c of Porter Stemmer algorithm\n",
    "\n",
    "print(\"test step 1.B  :> \")\n",
    "print(\"motoring -> \"+ str( stepOneB(\"motoring  \").lower() ) )\n",
    "print(\"plastered  -> \"+ str( stepOneB(\"plastered\").lower() ) )\n",
    "print(\"agreed  -> \"+ str( stepOneB(\"agreed   \").lower() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1.c conditions included dictionary\n",
    "stepOneCdict = {\"Y\":\"I\"}\n",
    "\n",
    "### STEP 1.C OF Porter Stemmer algorithm\n",
    "\n",
    "#use CalMeasure() to get the measure\n",
    "\n",
    "def stepOnec(word):\n",
    "    word = word.upper().strip()\n",
    "   \n",
    "    #first resolve issues with 1 word suffix    \n",
    "    last1 = word[len(word)-1:]    \n",
    "    stem1 = word[:len(word)-1]\n",
    "    \n",
    "    if( (last1 == \"Y\") and (CalMeasure(word)==1) ):\n",
    "        \n",
    "        word =  stem1 + stepOneCdict[last1]\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test step 1.C :> \n",
      "happy  -> happi\n",
      "sky   -> sky\n"
     ]
    }
   ],
   "source": [
    "#check step 1. c Porter Stemmer algorithm\n",
    "\n",
    "print(\"test step 1.C :> \")\n",
    "print(\"happy  -> \"+ str( stepOnec(\"happi   \").lower() ) )\n",
    "print(\"sky   -> \"+ str( stepOnec(\"sky \").lower() ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "               ### STEP 2  OF Porter Stemmer algorithm\n",
    "\n",
    "\n",
    "# step 2 conditions included dictionary\n",
    "stepTwodict = {\n",
    "    \"ATIONAL\":\"ATE\",\n",
    "    \"TIONAL\" :\"TION\",\n",
    "    \"ENCI\":\"ENCE\",\n",
    "    \"ANCI\": \"ANCE\" ,\n",
    "    \"IZER\" :\"IZE\" ,\n",
    "    \"ABLI\" : \"ABLE\", \n",
    "    \"ALLI\":\"AL\" ,\n",
    "    \"ENTLI\" : \"ENT\", \n",
    "    \"ELI\" :\"E\" ,\n",
    "    \"OUSLI\" : \"OUS\",\n",
    "    \"IZATION\" :\"IZE\" ,\n",
    "    \"ATION\" :  \"ATE\",    \n",
    "    \"ATOR\" : \"ATE\", \n",
    "    \"ALISM\" : \"AL\",\n",
    "    \"IVENESS\" : \"IVE\",\n",
    "    \"FULNESS\" :\"FUL\",\n",
    "    \"OUSNESS\" :\"OUS\",\n",
    "    \"ALITI\" : \"AL\",\n",
    "    \"IVITI\" : \"IVE\",\n",
    "    \"BILITI\" : \"BLE\" \n",
    "    \n",
    "}  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### STEP 2  OF Porter Stemmer algorithm\n",
    "\n",
    "#use CalMeasure() to get the measure\n",
    "\n",
    "def stepTwo(word):\n",
    "    \n",
    "    word = word.upper().strip()\n",
    "    \n",
    "    ##check whether the last words satisfies the step 2 conditions in the dictionary\n",
    "    for upto  in range(7,2,-1):\n",
    "        if(len(word) >= upto):\n",
    "            stem = word[:len(word)-upto]\n",
    "            last = word[len(word)-upto :]\n",
    "\n",
    "            if ( (last in stepTwodict.keys()) and (CalMeasure(word)>0)) :\n",
    "\n",
    "                word =  stem + stepTwodict[last]\n",
    "                return word\n",
    "            \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test step 2 :> \n",
      "relational  -> relate\n",
      "conditional   -> condition\n",
      "analogousli  -> agreed\n"
     ]
    }
   ],
   "source": [
    "print(\"test step 2 :> \")\n",
    "print(\"relational  -> \"+ str( stepTwo(\"relational\").lower() ) )\n",
    "print(\"conditional   -> \"+ str( stepTwo(\"conditional\").lower() ) )\n",
    "print(\"analogousli  -> \"+ str( stepTwo(\"agreed   \").lower() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "               ### STEP 3  OF Porter Stemmer algorithm\n",
    "\n",
    "\n",
    "# step 3 conditions included dictionary\n",
    "\n",
    "stepThreeCdict = {\n",
    "    \n",
    "        \"ICATE\" : \"IC\" ,\n",
    "        \"ATIVE\" : \"\",\n",
    "        \"ALIZE\" :\"AL\", \n",
    "        \"ICITI\" : \"IC\",\n",
    "        \"ICAL\"  : \"IC\",\n",
    "        \"FUL\" :\"\" ,\n",
    "        \"NESS\" :\"\"  \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### STEP 3  OF Porter Stemmer algorithm\n",
    "\n",
    "#use CalMeasure() to get the measure\n",
    "\n",
    "\n",
    "def stepThree(word):\n",
    "    \n",
    "    word = word.upper().strip()\n",
    "    \n",
    "    ##check whether the last words satisfies the step 2 conditions in the dictionary\n",
    "    for upto  in range(5,2,-1):\n",
    "        if(len(word) >= upto):\n",
    "            stem = word[:len(word)-upto]\n",
    "            last = word[len(word)-upto :]\n",
    "\n",
    "            if ( (last in stepThreeCdict.keys()) and (CalMeasure(word)>0)) :\n",
    "\n",
    "                word =  stem + stepThreeCdict[last]\n",
    "                return word\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test step 3 :> \n",
      "triplicate   -> triplic\n",
      "formalize    -> formal\n",
      "goodness   -> good\n"
     ]
    }
   ],
   "source": [
    "print(\"test step 3 :> \")\n",
    "print(\"triplicate   -> \"+ str( stepThree(\"triplicate \").lower() ) )\n",
    "print(\"formalize    -> \"+ str( stepThree(\"formalize \").lower() ) )\n",
    "print(\"goodness   -> \"+ str( stepThree(\"goodness\").lower() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "               ### STEP 4 OF Porter Stemmer algorithm\n",
    "\n",
    "\n",
    "# step 4 conditions included dictionary\n",
    "\n",
    "stepFourdict = {\n",
    "    \n",
    "    \"AL\" : \"\",\n",
    " \"ANCE\" : \"\",\n",
    " \"ENCE\" : \"\",\n",
    " \"ER\" : \"\",\n",
    " \"IC\" : \"\",\n",
    " \"ABLE\" : \"\",\n",
    " \"IBLE\" : \"\",\n",
    " \"ANT\" : \"\",\n",
    " \"EMENT\" : \"\",\n",
    " \"MENT\" : \"\",\n",
    " \"ENT\" : \"\",\n",
    "\"ION\" : \"\",\n",
    " \"OU\" : \"\",\n",
    " \"ISM\" : \"\",\n",
    " \"ATE\" : \"\",\n",
    " \"ITI\" : \"\",\n",
    " \"OUS\" : \"\",\n",
    " \"IVE\" : \"\",\n",
    " \"IZE\" : \"\"  \n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    " ### STEP 4  OF Porter Stemmer algorithm\n",
    "\n",
    "\n",
    "# step 4 conditions included dictionary\n",
    "\n",
    "\n",
    "#use CalMeasure() to get the measure\n",
    "#use CheckLastWord() to check whether the given word end in the given letter\n",
    "\n",
    "def stepFour(word):\n",
    "    \n",
    "    word = word.upper().strip()\n",
    "    \n",
    "    for upto  in range(5,1,-1):\n",
    "       \n",
    "        if(len(word) >= upto):\n",
    "            \n",
    "            stem = word[:len(word)-upto]\n",
    "            last = word[len(word)-upto :]\n",
    "            \n",
    "            if( (last == \"ION\") and ( (CheckLastWord(stem,\"S\")) or (CheckLastWord(stem,\"T\")) )):\n",
    "                word =  stem + stepFourdict[last]\n",
    "                return word\n",
    "            \n",
    "            elif ( (last in stepFourdict.keys()) and (CalMeasure(word)>1)) :\n",
    "                \n",
    "                word =  stem + stepFourdict[last]\n",
    "                return word\n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test step 4 :> \n",
      "revival    -> reviv\n",
      "gyroscopic     -> gyroscop\n",
      "activate    -> activ\n"
     ]
    }
   ],
   "source": [
    "#test step 4 \n",
    "print(\"test step 4 :> \")\n",
    "print(\"revival    -> \"+ str( stepFour(\"revival  \").lower() ) )\n",
    "print(\"gyroscopic     -> \"+ str( stepFour(\"gyroscopic \").lower() ) )\n",
    "print(\"activate    -> \"+ str( stepFour(\"activate \").lower() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP 5.a  OF Porter Stemmer algorithm\n",
    "\n",
    "\n",
    "# step 5.a conditions included dictionary\n",
    "\n",
    "#use CalMeasure() to get the measure\n",
    "#use CheckCVC() to check  the stem ends cvc, where the second c is not W, X or Y\n",
    "\n",
    "\n",
    "stepFivedict={\"E\":\"\"}\n",
    "\n",
    "def stepFivea(word):\n",
    "    word = word.upper().strip()\n",
    "    stem1 = word[:len(word)-1]\n",
    "    last1 = word[len(word)-1 :]\n",
    "    \n",
    "    if( (last1 == \"E\") and (CalMeasure(word)>1) ):\n",
    "        word = stem1 + stepFivedict[last1]\n",
    "        return word\n",
    "    \n",
    "    if( (last1 == \"E\") and (CalMeasure(word)== 1) and (CheckCVC(stem1)==False) ):\n",
    "        word = stem1 + stepFivedict[last1]\n",
    "        return word\n",
    "    \n",
    "    return word\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test step 5.a :> \n",
      "probate     -> probat\n",
      "cease       -> ceas\n"
     ]
    }
   ],
   "source": [
    "#test step 5.a \n",
    "print(\"test step 5.a :> \")\n",
    "print(\"probate     -> \"+ str( stepFivea(\"probate   \").lower() ) )\n",
    "print(\"cease       -> \"+ str( stepFivea(\"cease  \").lower() ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### STEP 5.b  OF Porter Stemmer algorithm\n",
    "\n",
    "#use CalMeasure() to get the measure\n",
    "#use CheckLastWord() to check whether the given word end in the given letter\n",
    "#use CheckD() to check whether  stem ends with a double consonant \n",
    "\n",
    "\n",
    "def stepFiveb(word):\n",
    "    word = word.upper().strip()\n",
    "    stem1 = word[:len(word)-1]\n",
    "    last1 = word[len(word)-1 :]\n",
    "    \n",
    "    if( (CalMeasure(word)>1) and (CheckD(word)==True) and (CheckLastWord(word,\"L\")==True)  ):\n",
    "        word = stem1 \n",
    "    \n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test step 5.b :> \n",
      "controll     -> controll\n"
     ]
    }
   ],
   "source": [
    "#test step 5.b\n",
    "print(\"test step 5.b :> \")\n",
    "print(\"controll     -> \"+ str( stepThree(\"controll   \").lower() ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.\tBuild module to apply case folding i.e. convert words to lower case. \n",
    "\n",
    "def caseFolding(word):\n",
    "    return word.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test case folding  \n",
      "ERT  --> ert\n"
     ]
    }
   ],
   "source": [
    "     #check case folding\n",
    "print(\"test case folding  \")\n",
    "print(\"ERT  --> \" + str( caseFolding(\"ERT\") ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Porter stemmer algorithm full funtion after collecting all the steps\n",
    "\n",
    "def Porter_Stemming(wordneed):\n",
    "    #test case pythonly\n",
    "    \n",
    "    if(wordneed.strip()==\"\"):\n",
    "        return None\n",
    "    word = wordneed\n",
    "    \n",
    "    word = stepOneA(word)\n",
    "    \n",
    "    word = stepOneB(word)\n",
    "   \n",
    "    word = stepOnec(word)\n",
    "    \n",
    "    word = stepTwo(word)\n",
    "    \n",
    "    word = stepThree(word)\n",
    "    \n",
    "    word = stepFour(word)\n",
    "    \n",
    "    word = stepFivea(word)\n",
    "    \n",
    "    word = stepFiveb(word)\n",
    "    \n",
    "    #use the created lower case module\n",
    "    \n",
    "    return caseFolding(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Poster Stemmer \n",
      "python --> python\n",
      "pythoner --> python\n",
      "pythonly--> pythonli\n",
      "important--> import\n",
      "poorly--> poorli\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Poster Stemmer \")\n",
    "print (\"python --> \" + Porter_Stemming(\"python\")) \n",
    "print (\"pythoner --> \" + Porter_Stemming(\"pythoner\") )\n",
    "print (\"pythonly--> \"+ Porter_Stemming(\"pythonly\") )\n",
    "print (\"important--> \"+ Porter_Stemming(\"important \") )\n",
    "print (\"poorly--> \"+Porter_Stemming(\"poorly\") )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.\tBuild inverted index and posting list as python dictionary.\n",
    "\n",
    "\n",
    "#get the output of getTermSent()\n",
    "output = getTermSent()\n",
    "\n",
    "#copy the tokenized terms to a dictionary\n",
    "term_doc_dict = output[0]\n",
    "\n",
    "#insert the keys to the posting list \n",
    "#output ---------> inverted_index_doc : {term : {doc frequency : [Posting List] }}\n",
    "inverted_index_doc ={}\n",
    "\n",
    "def build_inverted_index(term_doc):\n",
    "    \n",
    "    inverted_index_doc ={}\n",
    "    #loop each word to stemming and insert it to the inverted_index_doc\n",
    "    for term in term_doc.keys():\n",
    "        \n",
    "        #get the stem termed for build module by calling Porter_Stemming\n",
    "        stem_term = Porter_Stemming(term)\n",
    "        \n",
    "        if(stem_term is None):\n",
    "            continue\n",
    "        inverted_index_doc[stem_term] ={len(term_doc[term]):term_doc[term]}\n",
    "        \n",
    "        \n",
    "    return   inverted_index_doc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bahia': {1: ['1']},\n",
       " 'cocoa': {1: ['1']},\n",
       " 'review': {1: ['1']},\n",
       " 'show': {1: ['6']},\n",
       " 'continu': {1: ['1']},\n",
       " 'throughout': {1: ['1']},\n",
       " 'the': {4: ['1', '5', '6', '9']},\n",
       " 'week': {1: ['1']},\n",
       " 'in': {3: ['1', '6', '9']},\n",
       " 'zone': {1: ['1']},\n",
       " 'alleviat': {1: ['1']},\n",
       " 'drought': {1: ['1']},\n",
       " 'sinc': {1: ['1']},\n",
       " 'earli': {1: ['1']},\n",
       " 'january': {2: ['1', '5']},\n",
       " 'and': {3: ['1', '5', '6']},\n",
       " 'improv': {1: ['1']},\n",
       " 'prospect': {1: ['1']},\n",
       " 'for': {4: ['1', '5', '6', '9']},\n",
       " 'com': {1: ['1']},\n",
       " 'temporao': {1: ['1']},\n",
       " 'although': {1: ['1']},\n",
       " 'norm': {1: ['1']},\n",
       " 'humidity': {1: ['1']},\n",
       " 'level': {1: ['5']},\n",
       " 'have': {2: ['1', '5']},\n",
       " 'not': {1: ['1']},\n",
       " 'been': {1: ['1']},\n",
       " 'restor': {1: ['1']},\n",
       " 'comissaria': {1: ['1']},\n",
       " 'smith': {1: ['1']},\n",
       " 'said': {2: ['1', '9']},\n",
       " 'it': {1: ['1']},\n",
       " 'weekli': {1: ['1']},\n",
       " 'dry': {1: ['1']},\n",
       " 'period': {1: ['1']},\n",
       " 'mean': {1: ['1']},\n",
       " 'will': {1: ['1']},\n",
       " 'be': {1: ['1']},\n",
       " 'late': {1: ['1']},\n",
       " 'thi': {1: ['1']},\n",
       " 'year': {1: ['1']},\n",
       " 'arriv': {1: ['1']},\n",
       " 'end': {1: ['1']},\n",
       " 'february': {3: ['1', '5', '6']},\n",
       " '22': {1: ['1']},\n",
       " 'were': {2: ['1', '6']},\n",
       " '155221': {1: ['1']},\n",
       " 'bag': {1: ['1']},\n",
       " 'of': {3: ['1', '6', '9']},\n",
       " '60': {1: ['1']},\n",
       " 'kilo': {1: ['1']},\n",
       " 'mak': {1: ['1']},\n",
       " 'a': {4: ['1', '5', '6', '9']},\n",
       " 'cumul': {1: ['1']},\n",
       " 'tot': {2: ['1', '6']},\n",
       " 'season': {1: ['1']},\n",
       " '593': {1: ['1']},\n",
       " 'mln': {2: ['1', '9']},\n",
       " 'against': {1: ['1']},\n",
       " '581': {1: ['1']},\n",
       " 'at': {2: ['1', '9']},\n",
       " 'same': {1: ['1']},\n",
       " 'stage': {1: ['1']},\n",
       " 'last': {1: ['1']},\n",
       " 'again': {1: ['1']},\n",
       " 'seem': {1: ['1']},\n",
       " 'that': {1: ['1']},\n",
       " 'deliv': {1: ['1']},\n",
       " 'on': {1: ['1']},\n",
       " 'consign': {1: ['1']},\n",
       " 'wa': {1: ['1']},\n",
       " 'includ': {1: ['1']},\n",
       " 'figur': {2: ['1', '6']},\n",
       " 'there': {1: ['1']},\n",
       " 'i': {1: ['5']},\n",
       " 'still': {1: ['1']},\n",
       " 'some': {1: ['1']},\n",
       " 'doubt': {1: ['1']},\n",
       " 'to': {3: ['1', '6', '9']},\n",
       " 'how': {1: ['1']},\n",
       " 'much': {1: ['1']},\n",
       " 'old': {1: ['1']},\n",
       " 'crop': {2: ['1', '6']},\n",
       " 'avail': {2: ['1', '5']},\n",
       " 'harvest': {1: ['1']},\n",
       " 'ha': {1: ['1']},\n",
       " 'practically': {1: ['1']},\n",
       " 'come': {1: ['1']},\n",
       " 'an': {2: ['1', '9']},\n",
       " 'with': {1: ['1']},\n",
       " 'estim': {1: ['1']},\n",
       " 'around': {1: ['1']},\n",
       " '64': {1: ['1']},\n",
       " 'sale': {1: ['1']},\n",
       " 'stand': {1: ['1']},\n",
       " 'almost': {1: ['1']},\n",
       " '62': {1: ['1']},\n",
       " 'ar': {1: ['1']},\n",
       " 'few': {1: ['1']},\n",
       " 'hundr': {1: ['1']},\n",
       " 'thousand': {1: ['6']},\n",
       " 'hand': {1: ['1']},\n",
       " 'farm': {1: ['1']},\n",
       " 'middlemen': {1: ['1']},\n",
       " 'export': {2: ['1', '6']},\n",
       " 'processor': {1: ['1']},\n",
       " 'would': {1: ['1']},\n",
       " 'fit': {1: ['1']},\n",
       " 'shipp': {1: ['1']},\n",
       " 'now': {1: ['1']},\n",
       " 'experienc': {1: ['1']},\n",
       " 'dificulti': {1: ['1']},\n",
       " 'obtain': {1: ['1']},\n",
       " 'superior': {1: ['1']},\n",
       " 'certif': {1: ['1']},\n",
       " 'view': {1: ['1']},\n",
       " 'low': {1: ['1']},\n",
       " 'quality': {1: ['1']},\n",
       " 'ov': {1: ['1']},\n",
       " 'rec': {1: ['1']},\n",
       " 'sold': {1: ['1']},\n",
       " 'good': {1: ['1']},\n",
       " 'part': {1: ['1']},\n",
       " 'their': {2: ['1', '6']},\n",
       " 'held': {1: ['1']},\n",
       " 'spot': {1: ['1']},\n",
       " 'bean': {1: ['1']},\n",
       " 'price': {1: ['5']},\n",
       " 'rose': {1: ['1']},\n",
       " '340': {1: ['1']},\n",
       " '350': {1: ['1']},\n",
       " 'cruzado': {1: ['1']},\n",
       " 'per': {2: ['1', '5']},\n",
       " 'arroba': {1: ['1']},\n",
       " '15': {1: ['1']},\n",
       " 'reluct': {1: ['1']},\n",
       " 'off': {1: ['1']},\n",
       " 'nearbi': {1: ['1']},\n",
       " 'ship': {1: ['6']},\n",
       " 'onli': {1: ['1']},\n",
       " 'limit': {1: ['1']},\n",
       " 'book': {1: ['1']},\n",
       " 'march': {2: ['1', '6']},\n",
       " '1750': {1: ['1']},\n",
       " '1780': {1: ['1']},\n",
       " 'dlr': {1: ['1']},\n",
       " 'tonn': {1: ['6']},\n",
       " 'port': {1: ['1']},\n",
       " 'nam': {1: ['1']},\n",
       " 'new': {1: ['1']},\n",
       " 'also': {3: ['1', '6', '9']},\n",
       " 'light': {1: ['1']},\n",
       " 'all': {1: ['1']},\n",
       " 'open': {1: ['1']},\n",
       " 'junejuly': {1: ['1']},\n",
       " 'go': {1: ['1']},\n",
       " '1850': {1: ['1']},\n",
       " '1880': {1: ['1']},\n",
       " '35': {1: ['1']},\n",
       " '45': {1: ['1']},\n",
       " 'und': {1: ['1']},\n",
       " 'york': {1: ['1']},\n",
       " 'juli': {2: ['1', '5']},\n",
       " 'augsept': {1: ['1']},\n",
       " '1870': {1: ['1']},\n",
       " '1875': {1: ['1']},\n",
       " 'fob': {1: ['1']},\n",
       " 'routin': {1: ['1']},\n",
       " 'butt': {1: ['1']},\n",
       " 'made': {1: ['1']},\n",
       " 'marchapril': {1: ['1']},\n",
       " '4340': {1: ['1']},\n",
       " '4345': {1: ['1']},\n",
       " '4350': {1: ['1']},\n",
       " 'aprilmay': {1: ['1']},\n",
       " 'went': {1: ['1']},\n",
       " '227': {1: ['1']},\n",
       " 'time': {1: ['1']},\n",
       " 'mai': {2: ['1', '6']},\n",
       " '4400': {1: ['1']},\n",
       " '4415': {1: ['1']},\n",
       " '4351': {1: ['1']},\n",
       " '4450': {1: ['1']},\n",
       " '228': {1: ['1']},\n",
       " 'sept': {1: ['1']},\n",
       " 'octdec': {1: ['1']},\n",
       " '4480': {1: ['1']},\n",
       " 'dec': {1: ['1']},\n",
       " 'destin': {1: ['1']},\n",
       " 'u': {2: ['1', '5']},\n",
       " 'covert': {1: ['1']},\n",
       " 'currency': {1: ['1']},\n",
       " 'area': {1: ['1']},\n",
       " 'uruguay': {1: ['1']},\n",
       " 'cake': {1: ['1']},\n",
       " 'regist': {1: ['1']},\n",
       " '785': {1: ['1']},\n",
       " '995': {1: ['1']},\n",
       " '753': {1: ['1']},\n",
       " 'aug': {1: ['1']},\n",
       " '039': {1: ['1']},\n",
       " 'buy': {1: ['1']},\n",
       " 'argentina': {1: ['1']},\n",
       " 'convert': {1: ['1']},\n",
       " 'liquor': {1: ['1']},\n",
       " 'sell': {1: ['1']},\n",
       " '2325': {1: ['1']},\n",
       " '2380': {1: ['1']},\n",
       " '2375': {1: ['1']},\n",
       " '125': {1: ['1']},\n",
       " '2400': {1: ['1']},\n",
       " 'currently': {1: ['1']},\n",
       " '613': {1: ['1']},\n",
       " '198687': {2: ['1', '6']},\n",
       " '106': {1: ['1']},\n",
       " '198788': {1: ['1']},\n",
       " 'fin': {1: ['1']},\n",
       " '28': {1: ['1']},\n",
       " 'expect': {1: ['1']},\n",
       " 'publish': {1: ['1']},\n",
       " 'by': {1: ['1']},\n",
       " 'brazilian': {1: ['1']},\n",
       " 'trade': {1: ['1']},\n",
       " 'commiss': {1: ['1']},\n",
       " 'aft': {2: ['1', '5']},\n",
       " 'carniv': {1: ['1']},\n",
       " 'which': {1: ['1']},\n",
       " 'midday': {1: ['1']},\n",
       " '27': {1: ['1']},\n",
       " 'nate': {1: ['5']},\n",
       " 'averag': {1: ['5']},\n",
       " 'farmerown': {1: ['5']},\n",
       " 'reserv': {1: ['5']},\n",
       " 'agricultur': {1: ['5']},\n",
       " 'depart': {1: ['5']},\n",
       " 'report': {1: ['5']},\n",
       " 'fiveday': {1: ['5']},\n",
       " 'through': {1: ['5']},\n",
       " '25': {2: ['5', '9']},\n",
       " 'follow': {2: ['5', '6']},\n",
       " 'dlrsbusorghum': {1: ['5']},\n",
       " 'cwt': {1: ['5']},\n",
       " 'natl': {1: ['5']},\n",
       " 'loan': {1: ['5']},\n",
       " 'releas': {1: ['5']},\n",
       " 'call': {1: ['5']},\n",
       " 'avg': {1: ['5']},\n",
       " 'ratex': {1: ['5']},\n",
       " 'wheat': {2: ['5', '6']},\n",
       " '255': {1: ['5']},\n",
       " '240': {1: ['5']},\n",
       " 'iv': {1: ['5']},\n",
       " '465': {1: ['5']},\n",
       " 'v': {1: ['5']},\n",
       " 'vi': {1: ['5']},\n",
       " '445': {1: ['5']},\n",
       " 'corn': {1: ['5']},\n",
       " '135': {1: ['5']},\n",
       " '192': {1: ['5']},\n",
       " '315': {1: ['5']},\n",
       " '325': {1: ['5']},\n",
       " 'x': {1: ['5']},\n",
       " '1986': {2: ['5', '6']},\n",
       " 'rate': {1: ['5']},\n",
       " 'oat': {1: ['5']},\n",
       " '124': {1: ['5']},\n",
       " '099': {1: ['5']},\n",
       " '165': {1: ['5']},\n",
       " 'barley': {1: ['5']},\n",
       " 'na': {1: ['5']},\n",
       " '156': {1: ['5']},\n",
       " '265': {1: ['5']},\n",
       " 'sorghum': {2: ['5', '6']},\n",
       " '234': {1: ['5']},\n",
       " '325y': {1: ['5']},\n",
       " '536': {1: ['5']},\n",
       " '554': {1: ['5']},\n",
       " 'ii': {1: ['5']},\n",
       " 'iii': {1: ['5']},\n",
       " 'matur': {1: ['5']},\n",
       " 'reflect': {1: ['5']},\n",
       " 'grain': {1: ['6']},\n",
       " 'ent': {1: ['5']},\n",
       " 'oct': {1: ['5']},\n",
       " '6': {1: ['5']},\n",
       " '1981': {1: ['5']},\n",
       " 'feedgrain': {1: ['5']},\n",
       " '23': {2: ['5', '9']},\n",
       " 'wheatbarley': {1: ['5']},\n",
       " '51482': {1: ['5']},\n",
       " 'cornsorghum': {1: ['5']},\n",
       " '7182': {1: ['5']},\n",
       " 'cov': {1: ['5']},\n",
       " '19': {1: ['5']},\n",
       " '1984': {1: ['5']},\n",
       " 'x1986': {1: ['5']},\n",
       " 'ydlr': {1: ['5']},\n",
       " '100': {2: ['5', '6']},\n",
       " 'lb': {1: ['5']},\n",
       " 'nanot': {1: ['5']},\n",
       " 'argentin': {1: ['6']},\n",
       " 'grainoils': {1: ['6']},\n",
       " 'registr': {1: ['6']},\n",
       " 'board': {2: ['6', '9']},\n",
       " 'oils': {1: ['6']},\n",
       " 'product': {2: ['6', '9']},\n",
       " '11': {1: ['6']},\n",
       " 'those': {1: ['6']},\n",
       " 'futur': {1: ['6']},\n",
       " 'month': {1: ['6']},\n",
       " '198586': {1: ['6']},\n",
       " '12': {1: ['6']},\n",
       " 'bracket': {1: ['6']},\n",
       " 'bread': {1: ['6']},\n",
       " 'prev': {1: ['6']},\n",
       " '16558': {1: ['6']},\n",
       " 'feb': {1: ['6']},\n",
       " '8720': {1: ['6']},\n",
       " '1646': {1: ['6']},\n",
       " '26924': {1: ['6']},\n",
       " '41610': {1: ['6']},\n",
       " 'maiz': {1: ['6']},\n",
       " 'mar': {1: ['6']},\n",
       " '480': {1: ['6']},\n",
       " 'nil': {1: ['6']},\n",
       " 'sunflowers': {1: ['6']},\n",
       " '150': {1: ['6']},\n",
       " '79': {1: ['6']},\n",
       " 'soybean': {1: ['6']},\n",
       " '200': {1: ['6']},\n",
       " 'detail': {1: ['6']},\n",
       " 'subproduct': {1: ['6']},\n",
       " '399': {1: ['6']},\n",
       " '487': {1: ['6']},\n",
       " '132': {1: ['6']},\n",
       " 'apr': {1: ['6']},\n",
       " '1118': {1: ['6']},\n",
       " '827': {1: ['6']},\n",
       " 'lins': {1: ['6']},\n",
       " '348': {1: ['6']},\n",
       " '329': {1: ['6']},\n",
       " '68': {1: ['6']},\n",
       " '63': {1: ['6']},\n",
       " '808': {1: ['6']},\n",
       " '874': {1: ['6']},\n",
       " '1009': {1: ['6']},\n",
       " '451': {1: ['6']},\n",
       " '1661': {1: ['6']},\n",
       " '2185': {1: ['6']},\n",
       " '486': {1: ['6']},\n",
       " '615': {1: ['6']},\n",
       " '251': {1: ['6']},\n",
       " '145': {1: ['6']},\n",
       " '1498': {1: ['6']},\n",
       " '1453': {1: ['6']},\n",
       " 'veget': {1: ['6']},\n",
       " 'oil': {1: ['6']},\n",
       " 'sunoil': {1: ['6']},\n",
       " '374': {1: ['6']},\n",
       " '1073': {1: ['6']},\n",
       " '245': {1: ['6']},\n",
       " '32': {1: ['6']},\n",
       " 'jun': {1: ['6']},\n",
       " '1824': {1: ['6']},\n",
       " '1176': {1: ['6']},\n",
       " 'linoil': {1: ['6']},\n",
       " '159': {1: ['6']},\n",
       " '236': {1: ['6']},\n",
       " '204': {1: ['6']},\n",
       " '20': {1: ['6']},\n",
       " '618': {1: ['6']},\n",
       " '761': {1: ['6']},\n",
       " '37': {1: ['6']},\n",
       " '211': {1: ['6']},\n",
       " '90': {1: ['6']},\n",
       " '130': {1: ['6']},\n",
       " 'jul': {1: ['6']},\n",
       " '70': {1: ['6']},\n",
       " '558': {1: ['6']},\n",
       " '337': {1: ['6']},\n",
       " 'reut': {1: ['6']},\n",
       " 'champ': {1: ['9']},\n",
       " 'ltch': {1: ['9']},\n",
       " 'approv': {1: ['9']},\n",
       " 'stock': {1: ['9']},\n",
       " 'split': {1: ['9']},\n",
       " 'inc': {1: ['9']},\n",
       " 'director': {1: ['9']},\n",
       " 'twoforon': {1: ['9']},\n",
       " 'common': {1: ['9']},\n",
       " 'share': {1: ['9']},\n",
       " 'sharehold': {1: ['9']},\n",
       " 'record': {1: ['9']},\n",
       " 'april': {1: ['9']},\n",
       " '1': {1: ['9']},\n",
       " '1987': {1: ['9']},\n",
       " 'company': {1: ['9']},\n",
       " 'vot': {1: ['9']},\n",
       " 'recommend': {1: ['9']},\n",
       " 'annu': {1: ['9']},\n",
       " 'meet': {1: ['9']},\n",
       " 'increas': {1: ['9']},\n",
       " 'author': {1: ['9']},\n",
       " 'capit': {1: ['9']},\n",
       " 'from': {1: ['9']},\n",
       " 'five': {1: ['9']}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bui ld the inverted index and posting list by calling  build_inverted_index\n",
    "inverted_index_doc = build_inverted_index(term_doc_dict)\n",
    "\n",
    "#output ---------> inverted_index_doc : {term : {doc frequency : [Posting List] }}\n",
    "inverted_index_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.\tBuild a generalized module to merge any number of posting lists\n",
    "\n",
    "#Enter the input as list since the question say it need to merge any number of posting lists\n",
    "def Merge_posting(postinglist):\n",
    "    #check whethere there are minimum multiple list to intersection\n",
    "    if(len(postinglist) >= 2):\n",
    "        \n",
    "        #check whether the term contain in the matrix\n",
    "        if(postinglist[0] in inverted_index_doc.keys()):            \n",
    "            previous =  list(inverted_index_doc[postinglist[0]].values())[0] \n",
    "            \n",
    "        else:\n",
    "            return None;\n",
    "        \n",
    "        for terms in range(1,len(postinglist),1):\n",
    "              #check whether the term contain in the matrix\n",
    "            if(postinglist[terms] in inverted_index_doc.keys()): \n",
    "                current = list(inverted_index_doc[postinglist[terms]].values())[0]                 \n",
    "                previous = set(previous).intersection(current)\n",
    "                \n",
    "            else:\n",
    "                continue\n",
    "        return previous\n",
    "    else:\n",
    "        return [] \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and AND january AND the\n",
      "Enter term (N to quit):and\n",
      "Enter term (N to quit):january\n",
      "Enter term (N to quit):the\n",
      "Enter term (N to quit):N\n",
      "{'1', '5'}\n"
     ]
    }
   ],
   "source": [
    "#test the MERGE module\n",
    "#get numbers to input\n",
    "inp =\"\"\n",
    "termlist = []\n",
    "print(\"and AND january AND the\")\n",
    "while(True):\n",
    "    inp = str(input(\"Enter term (N to quit):\"))\n",
    "    if(inp.strip() != \"N\"):\n",
    "        termlist.append(inp)    \n",
    "    else :\n",
    "        break;\n",
    "    \n",
    "print(Merge_posting(termlist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================       Q2). ================ \n",
    "\n",
    "#1.\tCreate Permuterm Index for any given word.\t\n",
    "\n",
    "\n",
    "def Permuterm_index(word):\n",
    "    \n",
    "    initial = word.strip()\n",
    "    \n",
    "    #create the first permuation\n",
    "    word = word.strip() + \"$\"   \n",
    "    \n",
    "    #create the perumation list using comprehension for loop\n",
    "    permutermlist = [initial+\"$\"] + [word[i+1:] +word[:i]+ word[i]  for i in range(len(word)-1)] + [\"$\"+initial] \n",
    "    \n",
    "    return permutermlist\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test the Permuterm Index :> \n",
      "Enter a term :>> induwar\n",
      "['induwar$', 'nduwar$i', 'duwar$in', 'uwar$ind', 'war$indu', 'ar$induw', 'r$induwa', '$induwar', '$induwar']\n"
     ]
    }
   ],
   "source": [
    "print(\"Test the Permuterm Index :> \")\n",
    "inp =  str(input(\"Enter a term :>> \")).strip()\n",
    "print(Permuterm_index(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.\tFind out the Levenshtein distance between two words.\t\n",
    "\n",
    "#first implement findMini functions since it need for the Levenshtein_distance\n",
    "\n",
    "def findMin(num1,num2,num3):\n",
    "    \n",
    "    if((num1 < num2) and (num1 < num3)):\n",
    "        return num1\n",
    "    elif((num2 < num1) and (num2 < num3)):\n",
    "        return num2\n",
    "    else:\n",
    "        return  num3\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Levenshtein_distance(word1,word2):\n",
    "    #word1 = original #word2 that need to convert\n",
    "    \n",
    "    word1 = word1.strip()\n",
    "    word2 = word2.strip()\n",
    "    ##need to insert values to the all the rows\n",
    "    lev={}\n",
    "    \n",
    "    row = len(word2)+1\n",
    "    col = len(word1)+1\n",
    "    \n",
    "    ##first insert values to the empty string related rows and columns\n",
    "    for j in range(row):\n",
    "        temp = []\n",
    "        if(j==0):            \n",
    "            temp = [ini for ini in range(col)]\n",
    "            lev[j] = temp\n",
    "            continue\n",
    "        for i in range(col):            \n",
    "            if(i != 0):\n",
    "                temp.append(0)\n",
    "            elif(i == 0):\n",
    "                temp.append(j)\n",
    "        lev[j] = temp\n",
    "        \n",
    "    #now the calculation\n",
    "    \n",
    "    for b in range(1,row) :\n",
    "        \n",
    "        for a in range(1,col):            \n",
    "           \n",
    "            ## if both are not same get the min value from the diagonal\n",
    "            ## else get the diagonal value\n",
    "            if(word2[b-1] != word1[a-1]):\n",
    "                \n",
    "                mini = findMin(lev[b-1][a-1],lev[b-1][a],lev[b][a-1]) \n",
    "                lev[b][a] = mini +1\n",
    "            else:\n",
    "                lev[b][a] = lev[b-1][a-1]            \n",
    "    \n",
    "              \n",
    "    return lev,lev[row-1][col-1]\n",
    "                \n",
    "                \n",
    "                \n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Levenshtein distance between two words.:> \n",
      "Enter the word 1 :>> abcdef\n",
      "Enter the word 2 :>> azced\n",
      "Distance between abcdef & azced --->  3\n",
      "Matrix \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: [0, 1, 2, 3, 4, 5, 6],\n",
       " 1: [1, 0, 1, 2, 3, 4, 5],\n",
       " 2: [2, 1, 1, 2, 3, 4, 5],\n",
       " 3: [3, 2, 3, 1, 2, 3, 4],\n",
       " 4: [4, 3, 3, 2, 2, 2, 3],\n",
       " 5: [5, 4, 5, 3, 2, 3, 3]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test the Levenshtein_distance\n",
    "print(\"Test Levenshtein distance between two words.:> \")\n",
    "#levi = Levenshtein_distance(\"abcdef\",\"azced\")\n",
    "inp1 = str(input(\"Enter the word 1 :>> \")).strip()\n",
    "inp2 = str(input(\"Enter the word 2 :>> \")).strip()\n",
    "levi = Levenshtein_distance(inp1,inp2)\n",
    "print(\"Distance between abcdef & azced --->  \"+ str(levi[1]))\n",
    "print(\"Matrix \")\n",
    "levi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 3.\tImplement the SOUNDEX algorithm.\n",
    "\n",
    "## changing conditions as dictionary\n",
    "\n",
    "removedict2 = {\"B\":1,\"P\":1,\"F\":1,\"V\":1,\n",
    "               \"C\":2,\"S\":2,\"G\":2,\"J\":2,\"K\":2,\"Q\":2,\"X\":2,\"Z\":2,\n",
    "              \"D\":3,\"T\":3,\n",
    "               \"L\":4,\n",
    "               \"M\":5,\"N\":5,\n",
    "               \"R\":6\n",
    "              }\n",
    "removedict1 = {\"A\":0,\"E\":0,\"I\":0,\"O\":0,\"U\":0,\"H\":0,\"W\":0,\"Y\":0}\n",
    "              \n",
    "#>>> [\"Even\" if i%2==0 else \"Odd\" for i in range(8)]\n",
    "def SOUNDEX(wordinput):\n",
    "    \n",
    "    ##check if numbers exist in the word\n",
    "    status = False\n",
    "    status = [text.isdigit()  for text in wordinput.strip()]   \n",
    "    if(True in status):\n",
    "        return \"Cannot enter numbers \"\n",
    "    \n",
    "    ##strip & uppercase the words before modifications\n",
    "    #insert it to a list\n",
    "    wordlist =list(wordinput.upper().strip())\n",
    "    \n",
    "    #convert to zeros\n",
    "    temp1 = [out if out not in removedict1.keys() else str(removedict1[out]) for out in wordlist[1:] ]\n",
    "   \n",
    "    #change other letter to digits\n",
    "    temp2 = [out if out not in removedict2.keys() else str(removedict2[out]) for out in temp1 ]\n",
    "    \n",
    "    #check for consective numbers & for loop starts with the first index of temp2\n",
    "    len_temp2 =  len(temp2)\n",
    "    temp3 =  [temp2[out]  for out in range(1,len_temp2) if temp2[out] != temp2[out-1]  ]\n",
    "    \n",
    "    #insert first letter since for loop starts from the 1 index \n",
    "    #it wil not read the first index of temp2    \n",
    "    temp3.insert(0,wordlist[0])\n",
    "    \n",
    "    ##remove zeros    \n",
    "    temp4 = [out  for out in temp3 if out !=\"0\"   ]\n",
    "    \n",
    "    ##verify it has 4 letters at last \n",
    "    ## if not add zeros to the last and add it to the zero removed list (temp4)\n",
    "    if(len(temp4)<4):\n",
    "        needed_len = 4 - len(temp4)\n",
    "        temp4 = temp4 + [zero*0 for zero in range(needed_len)]\n",
    "        return temp4 \n",
    "    \n",
    "    ##verify it takes on the 4 letters\n",
    "    temp5 = [temp4[out]  for out in range(4) ]   \n",
    "    \n",
    "    return temp5\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Test SOUNDEX =====================\n",
      "Enter a term hermann\n",
      "['H', '6', '5', '5']\n"
     ]
    }
   ],
   "source": [
    "print(\"============Test SOUNDEX =====================\")\n",
    "inp =  str(input(\"Enter a term \")).strip()\n",
    "print(SOUNDEX(inp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
